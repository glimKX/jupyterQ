{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning from Udacity (Google)\n",
    "## Assignment 1\n",
    "Use notMNIST dataset to classify numbers\n",
    "<br>For starters, we will import the python libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\\c 200 200\n",
    "plt:.p.import[`matplotlib.pyplot];\n",
    "np:.p.import[`numpy];\n",
    "os:.p.import[`os];\n",
    "sys:.p.import[`sys];\n",
    "tarfile:.p.import[`tarfile];\n",
    "display:.p.import[`IPython.display][`:display];\n",
    "Image:.p.import[`IPython.display][`:Image];\n",
    "skimage:.p.import[`skimage];\n",
    "imageio:.p.import[`imageio];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download functionality\n",
    "After importing, we have to declare local python callbacks that we need.\n",
    "<br> In this example, we need a download progress hook to monitor the download progress, this is not necessary but useful to show that the function is running\n",
    "<br>\n",
    "<br> The hook is declared in python while the download functionality is embedpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/%declare download hook to monitor download progress\n",
    "p)last_percent_reported=None\n",
    "p)def download_progress_hook(count, blockSize, totalSize):\n",
    "  import sys\n",
    "  global last_percent_reported\n",
    "\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    " \n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "\n",
    "download_progress_hook:.p.get[`download_progress_hook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url:\"http://yaroslavvb.com/upload/notMNIST/\"\n",
    "dataStore:`:DeepLearning\n",
    "if[()~key dataStore;\n",
    "    -1\"Deep Learning Folder is missing, creating it now\";\n",
    "    system \"mkdir DeepLearning\"]\n",
    "notMNISTLarge:`notMNIST_large.tar.gz\n",
    "notMNISTSmall:`notMNIST_small.tar.gz\n",
    "\n",
    "downloadFile:{[file;dateStore;url] \n",
    "    urllib:.p.import[`urllib][`:request];\n",
    "    fileDir:` sv dataStore,file;\n",
    "    url:url,string file;\n",
    "    -1\"Check if \",1_string[fileDir],\" exists?\";\n",
    "    $[()~key fileDir;\n",
    "        [-1\"File is missing, initialise download\";\n",
    "        urllib[`:urlretrieve][url;1_string fileDir;`reporthook pykw download_progress_hook];\n",
    "        /0N! 1_string fileDir;\n",
    "        /httpGet[]\n",
    "        /filename:urlretrieve[url;1_string fileDir][];\n",
    "        -1\"\\nDownload Complete!\";];\n",
    "        -1\"File is present, skip download\";\n",
    "        ]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if DeepLearning/notMNIST_large.tar.gz exists?\r\n",
      "File is present, skip download\r\n",
      "\n",
      "\r\n",
      "Check if DeepLearning/notMNIST_small.tar.gz exists?\r\n",
      "File is present, skip download\r\n"
     ]
    }
   ],
   "source": [
    "downloadFile[notMNISTLarge;dataStore;url];\n",
    "-1\"\\n\";\n",
    "downloadFile[notMNISTSmall;dataStore;url];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untaring of data\n",
    "After the files are downloaded into the directory we want them in, we will have to untar the data\n",
    "<br> Note that the directory structure is known before hand.\n",
    "<br> If it was not known, we will have toe use recursive key to know its structure dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/Note This can be done with system tar -xzf in linux\n",
    "\n",
    "unTarFile:{[file;dateStore]\n",
    "    fileNoTar: `$first \".\" vs string file;\n",
    "    fileDir:` sv dataStore,file;\n",
    "    folderDir: 1_(first \".\" vs string fileDir),\"/.\";\n",
    "    -1\"Check if \",1_string[fileDir],\" exists?\";\n",
    "    if[10=count childDir:key parentDir:` sv (folderDirQ:hsym `$-2_folderDir),fileNoTar;\n",
    "        -1\"Extracted Files Exists! \\nSkipping Extraction for \",string file;\n",
    "        :` sv' parentDir,/:childDir];\n",
    "    if[file in key dateStore;\n",
    "        -1\"File exists, proceed to untar into \",-1_folderDir;\n",
    "        -1\"This will take a while, please be patient\";\n",
    "        tar:tarfile[`:open][1_string fileDir];\n",
    "        tar[`:extractall][`path pykw folderDir];\n",
    "        tar[`:close][];\n",
    "        ];\n",
    "    if[fileNoTar in key folderDirQ;\n",
    "       $[10=count childDir:key parentDir;\n",
    "            [-1\"Extraction Completed! \\nAll 10 Folders are Present\";` sv' parentDir,/:childDir];\n",
    "            -2\"Extraction Failed! \\nThere Are Missing Folders\";\n",
    "            ]\n",
    "        ]\n",
    "    \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if DeepLearning/notMNIST_small.tar.gz exists?\r\n",
      "Extracted Files Exists! \n",
      "Skipping Extraction for notMNIST_small.tar.gz\r\n",
      "\n",
      "\r\n",
      "Check if DeepLearning/notMNIST_large.tar.gz exists?\r\n",
      "Extracted Files Exists! \n",
      "Skipping Extraction for notMNIST_large.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "notMNISTSmallFolders:unTarFile[notMNISTSmall;dataStore]\n",
    "-1\"\\n\";\n",
    "notMNISTLargeFolders:unTarFile[notMNISTLarge;dataStore]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of Downloaded Data\n",
    "We might want to randomly look at some of the image files which we have downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`:DeepLearning/notMNIST_small/notMNIST_small/A`:DeepLearning/notMNIST_small/notMNIST_small/B`:DeepLearning/notMNIST_small/notMNIST_small/C\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`:DeepLearning/notMNIST_large/notMNIST_large/A`:DeepLearning/notMNIST_large/notMNIST_large/B`:DeepLearning/notMNIST_large/notMNIST_large/C\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB4klEQVR4nGWSS2tTURSFv73PuUWp2lHxEXEg1BeoiKERidYKggMzF8SZc0HHIgj+BJ3oyIKTjkTFkZUEESniA8GKFQTjg4CPtjSNSe4528HNTVpd08Xa++xvHQFArHzWI2SK3T/NleXFH08AcDLRtP81JQAuPDrddsF6SRHEgX72gISRwyTqWaPAfQ9oODQapTs12zaAEMzOVaIwA+C5ai27vjp2xTr2a6sHAhMk6V3nQ8/SUMJ48x1QRhfMPiT9mJDMW9uuoSAURzr2rOsGZmE7nlpmnsDkYZ8Bwu51QX+/QiFwnKGlGmFgFkl5+VMVtcJ+kxcNyRkQOQJUUUUpDXd455J8rMRNRRKqmAcmMeoh0EPkwoEtwTVeE5VUyjjK+3ZImqmdniJldknNa9y5F0+l0pz7mi89iVJFI57zlprFtW3FOI7DZyujYWZ5Y860/paID8lR1PSfuvR5SyPexsYwnb6pMX/r5TOBbCVcsE5c3Lwqds+6MRxEwTNBlOnGUA+e2HARkU/vMWD9vKV2TPJKHCWL3Xg7IzKeRpvro8Nz0brBKjhAJ13HHgy6hCKRLzNEQCdRqdH/lUH2BNNbTW8AH81a28jvFDYumD3doALgHxeSG9/yIzFWLu2q31nOyv0LVb36bNw8U3oAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACE0lEQVR4nF2TS0iUURTHf+fcOzOhaU5pIzjlo2h8jTZFYGpJBhFhSJo5i6DHVBbu3LRqF4Rt2iS0KGhhRJtodlKLHlJOIohBL7CIqCAKaqPZ5Hxfi5lvxjqry/2dx/+ec66QNXUaO9KhySl18Ey8gxLtLcOcKs3dqOoKp8oe8NEVQwERwF+BzdFtDwWHdX4E1KF9S9Ni97IFEDfyaUEdoTEFmEzd2Vel08mxtlzWbr+AcrsJNey601p9xNMjrN+BIpQkAxjaH1RxsVhFTFZq8wYEJXoNqzUz9QwdwgBZxcU/cYHAnBa13LjyJtg5IZkcdJBFwOXrvFM3/O2WxOd/GSD7FJEMiBtccuKBvZ1ijp7BwUsrLiBUa2pq8OYX+nwvtQAdYwAb/L6wuXnUuIkJCs1TdpeppSNq5PU5sRU/WljZ2U29sP0w9L8Ahj57yAKuvqtPpDPJgfTo8z7/0vB9xy6z0mqqsZHzHyMtjV1uL+YfJqDKzDFgMF2Wn7NmvUQMibdifDya/C8QEPV9OIhlbeakN2RoiHvKRp6gVhLpNZX5yHtuEQJiSt5vFVVS48TyNa/PGhGwXL6KUTb+aSgvz8OuMAKG2PRqI5ZLd2mV/FK2YUBZ9XQnRrUoFQ7XFjb2QCnGoOPHEeBCP3s0z6gcCELt2AlsoCLUt8/0hwuBQu3+pWAo+Szw+/TIxMJs1eO5wo/4C8YfgmLkINDyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABg0lEQVR4nHWQwWqTURCFvzn/bWytotHSRbGQKpVEBMGVFOoTuBIUBJeufAChCIJQBMGd6KKIXUsfQRBXpSCIFOpCkG4tiIIUEvvnzrhIYpO/6VndO9+dM+eOFUZkAF2/caF59vy87Wy8OrDgv0627j/f6sRAm5dNAHYvZput5kwCPDB7N790cGLjbuoCfOw9zmX2CI89q//yvEYC0I7/7eYIJRkE+zE9FdruTUtSKg6Ho9OPJ0t9VQCkNsOIue1GFHR9IgPqYMO41giD1WulenBUbojlT09dhsoKFICnJ89cKBgj0V25nYvxELN4WfdjIIXPrYRq4yGKh4uaPAYa0y1NUTEeXCMWNHOkxfvQrupcFXY08F2sbCizduUD3oMNnRnZbfBt90FbARiz8orrAhdTv5b0cyStUVt6O4EBEXu8jm4MqxwccqwfSZt6cXB+r+pU9SshINz16HtqZ9dhXo8ATGZ68abgfYxTe+sOwpZv3bxUT/3GP5u7+xlv//jy2S34BxFaxZI5gbhdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABt0lEQVR4nGWSvWtUURDFz7z73tugLkFUskRBBYsIGiN+pFMsBbHQwsrGj//Bzk4LC0HYaos0giGIf4A2FiqRiNoErTRos65fgaBk352ZY7Hvxd23U13uuTOc+d0jxFZZLOKv773VldddETgAluXubkaSzt6jswIZEqs3hSrptrgbAhmMjdm9xb351MH5+ZwCOsK7S2tSdm7yGjIAOLJEJcmCz5rYEm9gIqRpgu0LjCTZ53kklVWHmapnf9oAAaQ4kyQYLcPG53TgY5vURUFjDwWA440NiyJJMJzboQJY+Pl02FAOALgZzWmqvAiMrDJ5+PpzOknj2gWgguDJxy/Nxq59ARTXv5+edHrBavi033cWy7cOQBDG2dLVqRtvb+9HUo0t8jsPp2WyNXN6LicElPX7d2OdLY4tUd1NlZ10lG0IAY0HLEi68spYZ4ZTP2gkyZd1fDB038MBALNjIuBeHuKYGDB1tPzID2l1mSC4gB7zq62YAbDQqRuSk48HOYl8MZFWfTPHp5OdrUMnZlMEuEu6cnlzHF+hRvd+uwkZDrWZlqn+2p7D/9yWO2os1r91V18t/xaB4x9XcHPuCZCrPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "3#notMNISTSmallFolders\n",
    "3#notMNISTLargeFolders\n",
    "\n",
    "randomSelectionA:1_'string ` sv' notMNISTSmallFolders[0],/:2?key notMNISTSmallFolders 0\n",
    "randomSelectionB:1_'string ` sv' notMNISTSmallFolders[1],/:2?key notMNISTSmallFolders 1\n",
    "\n",
    "display each Image each randomSelectionA;\n",
    "display each Image each randomSelectionB;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image into DataSet\n",
    "\n",
    "Each of the folder represent a specific letter with its image inside\n",
    "<br>Each image is 28 X 28 in size, this represents 784 pixels with each image\n",
    "<br>We would have to store each of this 784 pixels into a numerical dataset which we will be able to work on with tensorFlow later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A| :DeepLearning/notMNIST_large/notMNIST_large/A\r\n",
       "B| :DeepLearning/notMNIST_large/notMNIST_large/B\r\n",
       "C| :DeepLearning/notMNIST_large/notMNIST_large/C\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/here we try to load the small image dataset with the help scikit image\n",
    ".utils.path:{$[x~k:key x;x;11h=type k;raze (.z.s ` sv x,)each k;()]}\n",
    "/note this func is highly recursive, do not perform on root, \n",
    "/this is useful is there is weird nesting but slow if we know the structure.\n",
    "notMINSTLargeNest:`:DeepLearning/notMNIST_large/notMNIST_large\n",
    "notMINSTLargeNest:notMINSTAlphabet!(` sv notMINSTLargeNest,) each notMINSTAlphabet:key notMINSTLargeNest\n",
    "/this contains the nested directory of each alphabet\n",
    "/going forward we need to load all the for each alphabet into a q table\n",
    "3#notMINSTLargeNest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already contains paths notMINSTLargeNestA\r\n",
      "Already contains paths notMINSTLargeNestB\r\n",
      "Already contains paths notMINSTLargeNestC\r\n",
      "Already contains paths notMINSTLargeNestD\r\n",
      "Already contains paths notMINSTLargeNestE\r\n",
      "Already contains paths notMINSTLargeNestF\r\n",
      "Already contains paths notMINSTLargeNestG\r\n",
      "Already contains paths notMINSTLargeNestH\r\n",
      "Already contains paths notMINSTLargeNestI\r\n",
      "Already contains paths notMINSTLargeNestJ\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       ":DeepLearning/notMNIST_large/notMNIST_large/A/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/A/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/B/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/B/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/C/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/C/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/D/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/D/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/E/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/E/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/F/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/F/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/G/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/G/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/H/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/H/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/I/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/I/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n",
       ":DeepLearning/notMNIST_large/notMNIST_large/J/ISBKYW1pcm9xdWFpICEudHRm.png :DeepLearning/notMNIST_large/notMNIST_large/J/IVNrZXRjaHkgVGltZXMgQm9sZC50dGY=.png\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/load directories\n",
    "/lazy implemetation of utils.path\n",
    "loadDir:{\n",
    "    {\n",
    "        @[{value;-1\"Already contains paths \",string x;};\n",
    "        x;\n",
    "        {x set .utils.path[(value -1_string x)`$-1#string x];-1\"Stored \",string x;y}x];\n",
    "    }each `$\"notMINSTLargeNest\",/:10#.Q.A\n",
    " }\n",
    "loadDir`;\n",
    "\n",
    "(2#value @) each `$\"notMINSTLargeNest\",/:10#.Q.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`largeTableA`largeTableB`largeTableC`largeTableD`largeTableE`largeTableF`largeTableG`largeTableH`largeTableI`largeTableJ\r\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "alphabet imgData\r\n",
       "----------------\r\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/create table to upsert data into\n",
    "(`$\"largeTable\",/:10#.Q.A) set\\: flip `alphabet`imgData!(();())\n",
    "largeTableA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/define func to read in each image and store them as q table\n",
    "imageIngestion:{[imgPath;t;alpha]\n",
    "    /read in img with imageio\n",
    "    @[{imgData:raze `float$imageio[`:imread][1_string x 0]`;\n",
    "        /validation to ensure that image is 28x28\n",
    "        $[784=count imgData;\n",
    "            x[1] upsert (x 2;imgData);\n",
    "            -1\"imgPath \",string[x 0],\" skipped\"];\n",
    "        };\n",
    "        (imgPath;t;alpha);\n",
    "        {-1\"imgPath \",1_string[x],\" couldn't be read, skipped \",.Q.s y}imgPath];    \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Image Ingestion largeTableA\n",
      "imgPath DeepLearning/notMNIST_large/notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png couldn't be read, skipped \"call: Could not find a format to read the specified file in mode 'i'\"\n",
      "\n",
      "imgPath DeepLearning/notMNIST_large/notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png couldn't be read, skipped \"call: Could not find a format to read the specified file in mode 'i'\"\n",
      "\n",
      "imgPath DeepLearning/notMNIST_large/notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png couldn't be read, skipped \"call: Could not find a format to read the specified file in mode 'i'\"\n",
      "\n",
      "Saving Down Flat File to HDB\n",
      "Start of Image Ingestion largeTableB\n",
      "imgPath DeepLearning/notMNIST_large/notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png couldn't be read, skipped \"call: Could not find a format to read the specified file in mode 'i'\"\n",
      "\n",
      "Saving Down Flat File to HDB\n",
      "Start of Image Ingestion largeTableC\n",
      "Saving Down Flat File to HDB\n",
      "Flat table exist, skipping ingestion for largeTableD\n",
      "Flat table exist, skipping ingestion for largeTableE\n",
      "Flat table exist, skipping ingestion for largeTableF\n",
      "Flat table exist, skipping ingestion for largeTableG\n",
      "Flat table exist, skipping ingestion for largeTableH\n",
      "Flat table exist, skipping ingestion for largeTableI\n",
      "Flat table exist, skipping ingestion for largeTableJ\n"
     ]
    }
   ],
   "source": [
    "/note that this is a very expensive operation and can take up to 30 mins for the entire ingestion\n",
    "/we will save the table down as a q table to make it efficient\n",
    "/if table has been saved down, it will be skipped\n",
    "ingestFunc:{[imgPath]\n",
    "    alpha:last ` vs first ` vs first imgPath;\n",
    "    t:`$\"largeTable\",string alpha;\n",
    "    $[()~key toStore:` sv `:DeepLearning/notMNIST_large/flatTable,t;\n",
    "     [-1\"Start of Image Ingestion \",string t;\n",
    "        imageIngestion[;t;alpha] each imgPath;\n",
    "        -1\"Saving Down Flat File to HDB\";\n",
    "        toStore set value t;\n",
    "        ];\n",
    "    -1\"Flat table exist, skipping ingestion for \",string t];    \n",
    "    } \n",
    "\n",
    "/running the ingestion function\n",
    "(ingestFunc value @) each \"notMINSTLargeNest\",/:10#.Q.A;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following Tables are in local drive: `largeTableA`largeTableB`largeTableC`largeTableD`largeTableE`largeTableF`largeTableG`largeTableH`largeTableI`largeTableJ\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A| 52909\r\n",
       "B| 52911\r\n",
       "C| 52912\r\n",
       "D| 105822\r\n",
       "E| 52912\r\n",
       "F| 52912\r\n",
       "G| 52912\r\n",
       "H| 52912\r\n",
       "I| 52912\r\n",
       "J| 52911\r\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1\"Following Tables are in local drive: \",.Q.s keptTable:keptTable where (keptTable:`#key `:DeepLearning/notMNIST_large/flatTable)like \"*largeTable*\";\n",
    "(`$'10#.Q.A)!(count get @)each ` sv' `:DeepLearning/notMNIST_large/flatTable,/:keptTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation of Data\n",
    "After the long and challenging process to ingest all the image data, now we have proper q hdb table with the image arrays to work with.\n",
    "\n",
    "To speed up machine learning process, we will adopt normalisation of data which is to subtract the mean followed by the std deviation.\n",
    "\n",
    "There are other methods of data manipulation which includes scaling to (0,1) but normalisation is chosen in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/get table and normalise the data\n",
    "\n",
    "/attempt to save down to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q 3.5",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
